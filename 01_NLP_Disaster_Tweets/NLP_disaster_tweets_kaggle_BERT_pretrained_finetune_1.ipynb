{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b02e4a7-ddd5-4bb1-a20d-f0d22f443ace",
   "metadata": {},
   "source": [
    "##### https://www.kaggle.com/competitions/nlp-getting-started\n",
    "##### Addison Howard, devrishi, Phil Culliton, Yufeng Guo. (2019). Natural Language Processing with Disaster Tweets\n",
    "###### the following notebook is very useful:\n",
    "###### https://www.kaggle.com/code/chayan8/sentiment-analysis-using-bert-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "ee0bc04c-62a7-4c05-9cd3-929b87a5e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "f8c83c58-f23f-4aa3-9e4c-ee702c3f7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset: Disaster: target==1. If no_Disaster: traget==0\n",
    "df_train = pd.read_csv(\"./data/train.csv\")\n",
    "df_test = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "9e39ae28-dbad-4115-a16c-ac256038bf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7613\n"
     ]
    }
   ],
   "source": [
    "tmp = df_train.sample(frac=1).reset_index(drop=True)\n",
    "print(len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "ba741430-d190-4fe8-bfb6-317283cba12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 5)\n",
      "(1613, 5)\n"
     ]
    }
   ],
   "source": [
    "# train val spilit from train-data\n",
    "df_train = tmp[:6000]\n",
    "df_val   = tmp[6000:]\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012dbe08-f9da-4015-ad7a-339906d9e723",
   "metadata": {},
   "source": [
    "##### https://huggingface.co/docs/transformers/model_doc/bert\n",
    "##### https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertForSequenceClassification.forward.example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4057b14-6c3c-45d0-89f8-8db1989d9578",
   "metadata": {},
   "source": [
    "### Ways to use BERT\n",
    "##### 1.Use BERT pre-trained model\n",
    "##### 2.Finetune BERT base for classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "340fb9a5-e597-44b4-9a05-5a7825004af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Example-1\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "# text = \"how are you doing\"\n",
    "# tokenized_text=tokenizer.tokenize(text)\n",
    "# print('tokenized_test:')\n",
    "# print(tokenized_text)\n",
    "# print()\n",
    "\n",
    "# encoded_text = tokenizer(text, padding=True,truncation=True, max_length=10, return_tensors='pt')\n",
    "# print('encoded_text:')\n",
    "# print(encoded_text)\n",
    "# print()\n",
    "\n",
    "# decoded_text=tokenizer.decode(encoded_text[\"input_ids\"][0],skip_special_tokens=False)\n",
    "# print('decoded_text:')\n",
    "# print(decoded_text)\n",
    "# print()\n",
    "\n",
    "# #embedded text in vector format\n",
    "# text_embeddings = model(**encoded_text)\n",
    "# print('embedded vector:')\n",
    "# print(text_embeddings[0])\n",
    "# print(text_embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "0f890ec7-c7a3-4f7e-b4f9-94d26bda57c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Example-2\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "# #padded/trimmed to custom token length\n",
    "# text = [\"how are you doing\",\\\n",
    "#         \"hello sir\",\\\n",
    "#         \"is there any whay to reach the destination without checking the google map and etc etc\"]\n",
    "\n",
    "# encoded_text = tokenizer(text, padding=True,truncation=True, max_length=10, return_tensors='pt')\n",
    "# print('encoded_text:')\n",
    "# print(encoded_text['input_ids'])\n",
    "# print(encoded_text['input_ids'].shape)\n",
    "# print()\n",
    "\n",
    "# decoded_text=tokenizer.decode(encoded_text[\"input_ids\"][0],skip_special_tokens=False)\n",
    "# print('decoded_text:')\n",
    "# print(tokenizer.decode(encoded_text[\"input_ids\"][0],skip_special_tokens=False))\n",
    "# print(tokenizer.decode(encoded_text[\"input_ids\"][1],skip_special_tokens=False))\n",
    "# print(tokenizer.decode(encoded_text[\"input_ids\"][2],skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a454d36-9dfd-4f94-a337-40adbc095cdb",
   "metadata": {},
   "source": [
    "#### Using Pre-trained Model\n",
    "##### https://huggingface.co/textattack/bert-base-uncased-yelp-polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "0c1750b8-b5c8-4bb0-bc6b-1ba8630fe9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: tensor([[ 0.6456, -0.8177]])\n",
      "predicted_class_id: 1\n",
      "id2label: LABEL_1\n",
      "loss: tensor(0.2082, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "------------------------------------------\n",
    "Large Yelp Review Dataset. This is a dataset for binary sentiment classification\n",
    "The Yelp reviews polarity dataset is constructed by considering stars 1 and 2 negative, and 3 and 4 positive.\n",
    "Negative polarity: class 1, positive polarity:class 2.\n",
    "predicted_class_id: 0 means Negative\n",
    "predicted_class_id: 1 means Positive\n",
    "------------------------------------------\n",
    "But for our disater tweets dataset. \n",
    "We will still try to use this pre-trained model to see the prediction accuracy\n",
    "predicted_class_id: 0 means Positive (No Disaster)\n",
    "predicted_class_id: 1 means Negative (Disaster)\n",
    "Hence use: logits*torch.tensor([-1])\n",
    "------------------------------------------\n",
    "'''\n",
    "#Example case for seq. classification\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\")\n",
    "\n",
    "### Example for BertForSequenceClassification\n",
    "inputs = tokenizer(\"Hello, my dog is dangerous\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_id = (logits*torch.tensor([-1])).argmax().item()\n",
    "model.config.id2label[predicted_class_id]\n",
    "\n",
    "labels = torch.tensor([0]) #specify label\n",
    "loss = model(**inputs, labels=labels).loss\n",
    "round(loss.item(), 2)\n",
    "\n",
    "print('logits:',logits)\n",
    "print('predicted_class_id:',predicted_class_id)\n",
    "print('id2label:',model.config.id2label[predicted_class_id])\n",
    "print('loss:',loss)\n",
    "\n",
    "# '''\n",
    "# Output:\n",
    "# logits: tensor([[ 4.3746, -3.9057]])\n",
    "# predicted_class_id: 0\n",
    "# id2label: LABEL_0\n",
    "# loss: tensor(0.0003, grad_fn=<NllLossBackward0>)\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "d38e47f7-5b8b-4f22-b6a7-9a7be42473b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df_train.text.values.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=100,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df_val.text.values.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    truncation=True,\n",
    "    max_length=100,\n",
    "    padding=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df_train.target.values)\n",
    "\n",
    "encoded_input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df_val.target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "26137df7-58f0-47fd-99d4-497e2f348351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### calculate the prediction accuracy for train-set \n",
    "# with torch.no_grad():\n",
    "#     logits = model(**encoded_data_train).logits\n",
    "# predicted_class_id=torch.argmax(logits*torch.tensor([-1]),dim=1)\n",
    "\n",
    "# # Calculate the number of correct predictions\n",
    "# correct_predictions = (predicted_class_id == labels_train).sum().item()\n",
    "# # Calculate accuracy\n",
    "# accuracy = correct_predictions / labels_train.size(0)  # total number of samples\n",
    "# print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "dbaeeb0e-62be-421f-8650-1a49c976a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### calculate the prediction accuracy for val-set \n",
    "# with torch.no_grad():\n",
    "#     logits = model(**encoded_data_val).logits\n",
    "# predicted_class_id=torch.argmax(logits*torch.tensor([-1]),dim=1)\n",
    "\n",
    "# # Calculate the number of correct predictions\n",
    "# correct_predictions = (predicted_class_id == labels_val).sum().item()\n",
    "# # Calculate accuracy\n",
    "# accuracy = correct_predictions / labels_val.size(0)  # total number of samples\n",
    "# print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde918b1-6918-4151-9d78-1638d2e7b13b",
   "metadata": {},
   "source": [
    "####  Finetune BERT for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "bbc1a788-9a07-41ce-a430-94850ca950f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "                                      'bert-base-uncased', \n",
    "                                      num_labels = 2,\n",
    "                                      output_attentions = False,\n",
    "                                      output_hidden_states = False\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "43cba4f0-d224-49b8-a2f1-a07607175faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(encoded_input_ids_train, \n",
    "                              attention_masks_train,\n",
    "                              labels_train)\n",
    "\n",
    "dataset_val = TensorDataset(encoded_input_ids_val, \n",
    "                            attention_masks_val,\n",
    "                           labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "98863c33-69f1-4e42-b54b-76f1f65d6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    sampler=RandomSampler(dataset_train),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val,\n",
    "    sampler=RandomSampler(dataset_val),\n",
    "    batch_size=len(labels_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "be272993-bb98-4455-92c2-ebba7fcbc760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vino/anaconda3/envs/pytorch23/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr = 1e-5,\n",
    "    eps = 1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "19381c15-ef4b-4e7b-afe0-c519ebae38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps = len(dataloader_train)*epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "71720874-bdb7-4f4b-a6d8-0d2f51e01ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "a4555744-87c9-4109-bc41-5fdd209f0d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "12c47af4-aa7d-491e-a803-3b878408d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "18cad481-0647-4a45-a23c-554fdaaec35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in tqdm(dataloader_val):\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "ec44276e-ca72-49e1-8a06-31175fa1404c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952e7097f3064dbf88a73992db61afc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss: 0.3494734355109803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83d6880da384c2fab240e49cb93e0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3902204632759094\n",
      "F1 Score (weighted): 0.8318329192114048\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader_train, \n",
    "                        desc='Epoch {:1d}'.format(epoch), \n",
    "                        leave=False, \n",
    "                        disable=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2]\n",
    "        }\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        loss_train_total +=loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
    "       \n",
    "    tqdm.write('\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "\n",
    "##save model\n",
    "#torch.save(model.state_dict(), './data/bert_disaster_tweets_finetuned_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "466423ed-9333-459a-a302-73e11c443c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.26%\n"
     ]
    }
   ],
   "source": [
    "### calculate the prediction accuracy for val-set \n",
    "with torch.no_grad():\n",
    "    logits = model(**encoded_data_val).logits\n",
    "predicted_class_id=torch.argmax(logits,dim=1)\n",
    "\n",
    "# Calculate the number of correct predictions\n",
    "correct_predictions = (predicted_class_id == labels_val).sum().item()\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / labels_val.size(0)  # total number of samples\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
