{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f506feee-98f0-4106-a53a-ccbff09b3ce3",
   "metadata": {},
   "source": [
    "### https://www.kaggle.com/competitions/drawing-with-llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9062a4b-55ec-493c-a31e-f03a3489a374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vino/anaconda3/envs/kaggle/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04c411</td>\n",
       "      <td>a starlit night over snow-covered peaks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>215136</td>\n",
       "      <td>black and white checkered pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3e2bc6</td>\n",
       "      <td>crimson rectangles forming a chaotic grid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61d7a8</td>\n",
       "      <td>burgundy corduroy pants with patch pockets and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6f2ca7</td>\n",
       "      <td>orange corduroy overalls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                        description\n",
       "0  04c411            a starlit night over snow-covered peaks\n",
       "1  215136                    black and white checkered pants\n",
       "2  3e2bc6          crimson rectangles forming a chaotic grid\n",
       "3  61d7a8  burgundy corduroy pants with patch pockets and...\n",
       "4  6f2ca7                           orange corduroy overalls"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "train_path = kagglehub.competition_download('drawing-with-llms', 'train.csv')\n",
    "train = pd.read_csv(train_path)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14045bdd-8b5c-483b-b17f-1fb34ffb0fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.2.15: Fast Qwen2 patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti SUPER. Max memory: 15.693 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:   0%|                                 | 0/4 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = (\n",
    "    None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    ")\n",
    "load_in_4bit = False # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",  # Llama-3.1 15 trillion tokens model 2x faster!\n",
    "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",  # We also uploaded 4bit for 405b!\n",
    "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\",  # New Mistral 12b 2x faster!\n",
    "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",  # Mistral v3 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3.5-mini-instruct\",  # Phi-3.5 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2-27b-bnb-4bit\",  # Gemma 2x faster!\n",
    "]  # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/Qwen2.5-Coder-7B-Instruct\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f6e2f5-ca36-40a4-922d-2f90ad2af3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "# Define your tokenizer with a flexible chat template\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template=\"chatml\",  # Flexible for multiple models (Zephyr, LLaMA, Mistral, etc.)\n",
    "    mapping={\n",
    "        \"role\": \"from\", \n",
    "        \"content\": \"value\", \n",
    "        \"user\": \"human\", \n",
    "        \"assistant\": \"gpt\"\n",
    "    },\n",
    "    map_eos_token=True,  # Ensures <|im_end|> maps to </s> for end-of-sentence\n",
    ")\n",
    "\n",
    "# Enable faster inference (2x speed up)\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "def get_svg_code(text):\n",
    "    \"\"\"\n",
    "    This function generates a minimal, valid SVG based on the provided text input.\n",
    "    \"\"\"\n",
    "\n",
    "    # Structured chat template for SVG generation request\n",
    "    messages = [\n",
    "        {\n",
    "            \"from\": \"system\", \n",
    "            \"value\": \"You are a helpful assistant specialized in generating minimal, valid SVG code\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"human\", \n",
    "            \"value\": f\"Now, create an SVG based on the following topic: {text}\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Apply the tokenizer and prepare the inputs for the model\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        padding=True,\n",
    "        truncation=False,\n",
    "        add_generation_prompt=True,  # Necessary for generation to work\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    # Create an attention mask to avoid padding interference during inference\n",
    "    attention_mask = (inputs != tokenizer.pad_token_id).int() \n",
    "\n",
    "    # Generate output using the model\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs,\n",
    "        attention_mask=attention_mask,\n",
    "        temperature=0.5,  # Low temperature for deterministic results\n",
    "        max_new_tokens=2048,  # Adjust max tokens if needed\n",
    "        use_cache=True\n",
    "    )\n",
    "    \n",
    "    # Decode and return the unformatted output (processed into a clean response)\n",
    "    unformatted_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return unformatted_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2bba70-5043-41a7-b7e5-63d85bf9bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "svg_code=get_svg_code(train['description'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a92fe1-0a2c-434e-b416-8996feaca5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=svg_code.split('assistant\\n')[1].split('<svg')[1]\n",
    "tmp='<svg'+tmp\n",
    "tmp=tmp+' </svg>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a87be-748d-4f27-97cf-5f9a1afea2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "993d8976-454b-4c58-8010-17ccaa6d1861",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tmp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# We can play with our Model and render its SVG output (don't export!)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SVG, display\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m display(SVG(\u001b[43mtmp\u001b[49m))\n",
      "\u001b[31mNameError\u001b[39m: name 'tmp' is not defined"
     ]
    }
   ],
   "source": [
    "# We can play with our Model and render its SVG output (don't export!)\n",
    "from IPython.display import SVG, display\n",
    "display(SVG(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8912d1fe-670d-4240-8853-2bb142a15e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f017df3-2f6a-44c4-8ad7-4a4f4c7fddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "<svg width=\"800\" height=\"600\" xmlns=\"http://www.w3.org/2000/svg\">\n",
    "  <!-- Background -->\n",
    "  <rect x=\"0\" y=\"0\" width=\"100%\" height=\"100%\" fill=\"#202020\" opacity=\"0.8\" />\n",
    "  \n",
    "  <!-- Snow-Covered Peaks -->\n",
    "  <polygon points=\"100,300 150,250 200,300 250,250 300,300 350,250 400,300\" fill=\"#FFFFFF\" />\n",
    "  <polygon points=\"500,500 550,450 600,500 650,500 700,500 750,450 800,500\" fill=\"#FFFFFF\" />\n",
    "  \n",
    "  <!-- Moon -->\n",
    "  <circle cx=\"700\" cy=\"100\" r=\"50\" fill=\"#FFFFFF\" />\n",
    "  \n",
    "  <!-- Stars -->\n",
    "  <circle cx=\"100\" cy=\"200\" r=\"2\" fill=\"#FFFFFF\" />\n",
    "  <circle cx=\"200\" cy=\"100\" r=\"2\" fill=\"#FFFFFF\" />\n",
    "  <circle cx=\"300\" cy=\"300\" r=\"2\" fill=\"#FFFFFF\" />\n",
    "  <circle cx=\"400\" cy=\"150\" r=\"2\" fill=\"#FFFFFF\" />\n",
    "  <circle cx=\"500\" cy=\"250\" r=\"2\" fill=\"#FFFFFF\" />\n",
    "  <circle cx=\"600\" cy=\"400\" r=\"2\" fill=\"#FFFFFF\" />\n",
    "  <circle cx=\"700\" cy=\"200\" r=\"2\" fill=\"#FFFFFF\" />\n",
    "  <circle cx=\"800\" cy=\"100\" r=\"2\" fill=\"#FFFFFF\" />\n",
    "  \n",
    "  <!-- Text - Optional -->\n",
    "  <text x=\"10\" y=\"580\" font-family=\"Arial\" font-size=\"20\" fill=\"#FFFFFF\">Starlit Night Over Snow-Covered Peaks</text>\n",
    "</svg>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e12ffd-5807-4559-9b22-160a87a93877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 100 100\">\n",
       "  <!-- Background - snow-covered peaks -->\n",
       "  <rect x=\"0\" y=\"0\" width=\"100\" height=\"100\" fill=\"#ffffff\"/>\n",
       "  \n",
       "  <!-- Stars in the sky -->\n",
       "  <circle cx=\"20\" cy=\"30\" r=\"1\" fill=\"#ffffff\"/>\n",
       "  <circle cx=\"40\" cy=\"20\" r=\"1\" fill=\"#ffffff\"/>\n",
       "  <circle cx=\"60\" cy=\"25\" r=\"1\" fill=\"#ffffff\"/>\n",
       "  <circle cx=\"80\" cy=\"35\" r=\"1\" fill=\"#ffffff\"/>\n",
       "  <circle cx=\"30\" cy=\"50\" r=\"1\" fill=\"#ffffff\"/>\n",
       "  <circle cx=\"50\" cy=\"60\" r=\"1\" fill=\"#ffffff\"/>\n",
       "  <circle cx=\"70\" cy=\"55\" r=\"1\" fill=\"#ffffff\"/>\n",
       "  <circle cx=\"90\" cy=\"45\" r=\"1\" fill=\"#ffffff\"/>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import SVG, display\n",
    "\n",
    "# SVG code as a string\n",
    "svg_code = '''<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 100 100\">\n",
    "  <!-- Background - snow-covered peaks -->\n",
    "  <rect x=\"0\" y=\"0\" width=\"100\" height=\"100\" fill=\"#ffffff\" />\n",
    "  \n",
    "  <!-- Stars in the sky -->\n",
    "  <circle cx=\"20\" cy=\"30\" r=\"1\" fill=\"#ffffff\" />\n",
    "  <circle cx=\"40\" cy=\"20\" r=\"1\" fill=\"#ffffff\" />\n",
    "  <circle cx=\"60\" cy=\"25\" r=\"1\" fill=\"#ffffff\" />\n",
    "  <circle cx=\"80\" cy=\"35\" r=\"1\" fill=\"#ffffff\" />\n",
    "  <circle cx=\"30\" cy=\"50\" r=\"1\" fill=\"#ffffff\" />\n",
    "  <circle cx=\"50\" cy=\"60\" r=\"1\" fill=\"#ffffff\" />\n",
    "  <circle cx=\"70\" cy=\"55\" r=\"1\" fill=\"#ffffff\" />\n",
    "  <circle cx=\"90\" cy=\"45\" r=\"1\" fill=\"#ffffff\" />\n",
    "</svg>'''\n",
    "\n",
    "# Display the SVG\n",
    "display(SVG(data=svg_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e2d7c-92b9-4d29-8ca0-71025b85d26f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11175052,
     "sourceId": 89659,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.756759,
   "end_time": "2025-02-26T02:09:27.363350",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-26T02:09:20.606591",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
