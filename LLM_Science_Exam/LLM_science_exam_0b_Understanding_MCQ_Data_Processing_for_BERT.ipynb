{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea4478ec",
   "metadata": {
    "papermill": {
     "duration": 0.005068,
     "end_time": "2023-07-11T01:36:25.324996",
     "exception": false,
     "start_time": "2023-07-11T01:36:25.319928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Understanding MCQ Data Processing for BERT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b7b3c2e6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.057636,
     "end_time": "2023-07-11T01:36:25.387575",
     "exception": false,
     "start_time": "2023-07-11T01:36:25.329939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My pet always barks</td>\n",
       "      <td>it is a dog</td>\n",
       "      <td>it is a cat</td>\n",
       "      <td>it is a monkey</td>\n",
       "      <td>it is a horse</td>\n",
       "      <td>it is a rabbit</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>My pet always meow</td>\n",
       "      <td>it is a dog</td>\n",
       "      <td>it is a cat</td>\n",
       "      <td>it is a monkey</td>\n",
       "      <td>it is a horse</td>\n",
       "      <td>it is a rabbit</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               prompt            A            B               C  \\\n",
       "0   0  My pet always barks  it is a dog  it is a cat  it is a monkey   \n",
       "1   1   My pet always meow  it is a dog  it is a cat  it is a monkey   \n",
       "\n",
       "               D               E answer  \n",
       "0  it is a horse  it is a rabbit      A  \n",
       "1  it is a horse  it is a rabbit      B  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's import the public training set and take a look\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('./data/custom_example.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ace645db-0209-4293-8ca0-37746dc29e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 0\n",
      "prompt: My pet always barks\n",
      "A: it is a dog\n",
      "B: it is a cat\n",
      "C: it is a monkey\n",
      "D: it is a horse\n",
      "E: it is a rabbit\n",
      "answer: A\n"
     ]
    }
   ],
   "source": [
    "print('id:',train_df['id'].iloc[0])\n",
    "print('prompt:',train_df['prompt'].iloc[0])\n",
    "print('A:',train_df['A'].iloc[0])\n",
    "print('B:',train_df['B'].iloc[0])\n",
    "print('C:',train_df['C'].iloc[0])\n",
    "print('D:',train_df['D'].iloc[0])\n",
    "print('E:',train_df['E'].iloc[0])\n",
    "print('answer:',train_df['answer'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "55729adf",
   "metadata": {
    "papermill": {
     "duration": 0.888982,
     "end_time": "2023-07-11T01:36:26.281400",
     "exception": false,
     "start_time": "2023-07-11T01:36:25.392418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For convenience we'll turn our pandas Dataframe into a Dataset\n",
    "from datasets import Dataset\n",
    "train_ds = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "673a67c4-97d8-48ba-984e-b209f9a09e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ac098933-8185-43f2-87e4-49b9ca5bbb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'prompt': 'My pet always barks',\n",
       " 'A': 'it is a dog',\n",
       " 'B': 'it is a cat',\n",
       " 'C': 'it is a monkey',\n",
       " 'D': 'it is a horse',\n",
       " 'E': 'it is a rabbit',\n",
       " 'answer': 'A'}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7d406058",
   "metadata": {
    "papermill": {
     "duration": 2.342402,
     "end_time": "2023-07-11T01:36:28.636204",
     "exception": false,
     "start_time": "2023-07-11T01:36:26.293802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import pprint\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "598b5560",
   "metadata": {
    "papermill": {
     "duration": 0.533681,
     "end_time": "2023-07-11T01:36:29.175376",
     "exception": false,
     "start_time": "2023-07-11T01:36:28.641695",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d9d82a6ae94527abd1988f3786e1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We'll create a dictionary to convert option names (A, B, C, D, E) into indices and back again\n",
    "options = 'ABCDE'\n",
    "indices = list(range(5))\n",
    "\n",
    "option_to_index = {option: index for option, index in zip(options, indices)}\n",
    "index_to_option = {index: option for option, index in zip(options, indices)}\n",
    "\n",
    "def preprocess(example):\n",
    "    # The AutoModelForMultipleChoice class expects a set of question/answer pairs\n",
    "    # so we'll copy our question 5 times before tokenizing\n",
    "    first_sentence = [example['prompt']] * 5\n",
    "    \n",
    "    second_sentence = []\n",
    "    for option in options:\n",
    "        second_sentence.append(example[option])\n",
    "    \n",
    "    # Our tokenizer will turn our text into token IDs BERT can understand\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True)\n",
    "    tokenized_example['label'] = option_to_index[example['answer']]\n",
    "\n",
    "    return tokenized_example\n",
    "\n",
    "tokenized_train_ds = train_ds.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "defa0389-5368-4532-a723-6c906ccbed4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry 0: {'id': 0, 'input_ids': [[101, 2026, 9004, 2467, 11286, 2015, 102, 2009, 2003, 1037, 3899, 102], [101, 2026, 9004, 2467, 11286, 2015, 102, 2009, 2003, 1037, 4937, 102], [101, 2026, 9004, 2467, 11286, 2015, 102, 2009, 2003, 1037, 10608, 102], [101, 2026, 9004, 2467, 11286, 2015, 102, 2009, 2003, 1037, 3586, 102], [101, 2026, 9004, 2467, 11286, 2015, 102, 2009, 2003, 1037, 10442, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'label': 0}\n",
      "Entry 1: {'id': 1, 'input_ids': [[101, 2026, 9004, 2467, 2033, 5004, 102, 2009, 2003, 1037, 3899, 102], [101, 2026, 9004, 2467, 2033, 5004, 102, 2009, 2003, 1037, 4937, 102], [101, 2026, 9004, 2467, 2033, 5004, 102, 2009, 2003, 1037, 10608, 102], [101, 2026, 9004, 2467, 2033, 5004, 102, 2009, 2003, 1037, 3586, 102], [101, 2026, 9004, 2467, 2033, 5004, 102, 2009, 2003, 1037, 10442, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "#Loop through and print each entry in the dataset\n",
    "#Visualize the tokenised dataset\n",
    "for i in range(len(tokenized_train_ds)):\n",
    "    print(f\"Entry {i}: {tokenized_train_ds[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8e100e1c-2d47-46fd-9f24-fb2244a4bd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[101, 2026, 9004, 2467, 11286, 2015, 102, 2009, 2003, 1037, 3899, 102],\n",
       "  [101, 2026, 9004, 2467, 11286, 2015, 102, 2009, 2003, 1037, 4937, 102],\n",
       "  [101, 2026, 9004, 2467, 11286, 2015, 102, 2009, 2003, 1037, 10608, 102],\n",
       "  [101, 2026, 9004, 2467, 11286, 2015, 102, 2009, 2003, 1037, 3586, 102],\n",
       "  [101, 2026, 9004, 2467, 11286, 2015, 102, 2009, 2003, 1037, 10442, 102]],\n",
       " [[101, 2026, 9004, 2467, 2033, 5004, 102, 2009, 2003, 1037, 3899, 102],\n",
       "  [101, 2026, 9004, 2467, 2033, 5004, 102, 2009, 2003, 1037, 4937, 102],\n",
       "  [101, 2026, 9004, 2467, 2033, 5004, 102, 2009, 2003, 1037, 10608, 102],\n",
       "  [101, 2026, 9004, 2467, 2033, 5004, 102, 2009, 2003, 1037, 3586, 102],\n",
       "  [101, 2026, 9004, 2467, 2033, 5004, 102, 2009, 2003, 1037, 10442, 102]]]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elements\n",
    "tokenized_train_ds['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "39a57d92-b5a7-41e2-b307-b2cfd4c14d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]],\n",
       " [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]]]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elements\n",
    "tokenized_train_ds['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a4c102fe-798a-402f-908c-fca0199910b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elements\n",
    "tokenized_train_ds['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "65e6c1fd-0562-4464-926b-520daa0bdfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elements\n",
    "tokenized_train_ds['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0948cac1-fe9b-4451-8996-71d3f92f7901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Entry 0: [CLS] my pet always barks [SEP] it is a dog [SEP] [CLS] my pet always barks [SEP] it is a cat [SEP] [CLS] my pet always barks [SEP] it is a monkey [SEP] [CLS] my pet always barks [SEP] it is a horse [SEP] [CLS] my pet always barks [SEP] it is a rabbit [SEP]\n",
      "Decoded Entry 1: [CLS] my pet always meow [SEP] it is a dog [SEP] [CLS] my pet always meow [SEP] it is a cat [SEP] [CLS] my pet always meow [SEP] it is a monkey [SEP] [CLS] my pet always meow [SEP] it is a horse [SEP] [CLS] my pet always meow [SEP] it is a rabbit [SEP]\n"
     ]
    }
   ],
   "source": [
    "# Example: Decode the first example\n",
    "for i in range(len(tokenized_train_ds)):\n",
    "    # Access the input_ids for the ith example\n",
    "    input_ids = tokenized_train_ds[i]['input_ids']\n",
    "    \n",
    "    # If input_ids is a nested list, flatten it\n",
    "    if isinstance(input_ids[0], list):\n",
    "        input_ids = [item for sublist in input_ids for item in sublist]\n",
    "    \n",
    "    # Decode the input_ids\n",
    "    decoded_text = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "    \n",
    "    # Print the decoded text\n",
    "    print(f\"Decoded Entry {i}: {decoded_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6f670757-aa20-4a2e-a83f-e8523370f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example to Undestand:\n",
    "# from dataclasses import dataclass\n",
    "# from typing import Union, Optional\n",
    "# import torch\n",
    "# from transformers import PreTrainedTokenizerBase, BertTokenizer\n",
    "# from torch.utils.data import DataLoader\n",
    "# from datasets import Dataset\n",
    "\n",
    "# # Define the DataCollatorForMultipleChoice class\n",
    "# @dataclass\n",
    "# class DataCollatorForMultipleChoice:\n",
    "#     tokenizer: PreTrainedTokenizerBase\n",
    "#     padding: Union[bool, str] = True\n",
    "#     max_length: Optional[int] = None\n",
    "#     pad_to_multiple_of: Optional[int] = None\n",
    "    \n",
    "#     def __call__(self, features):\n",
    "#         label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n",
    "#         labels = [feature.pop(label_name) for feature in features]\n",
    "#         batch_size = len(features)\n",
    "#         num_choices = len(features[0]['input_ids'])  # Access the number of choices\n",
    "\n",
    "#         # Flatten the features for each choice\n",
    "#         flattened_features = []\n",
    "#         for feature in features:\n",
    "#             for i in range(num_choices):\n",
    "#                 flattened_features.append({\n",
    "#                     'input_ids': feature['input_ids'][i],\n",
    "#                     'attention_mask': feature['attention_mask'][i]\n",
    "#                 })\n",
    "        \n",
    "#         # Pad the sequences\n",
    "#         batch = self.tokenizer.pad(\n",
    "#             flattened_features,\n",
    "#             padding=self.padding,\n",
    "#             max_length=self.max_length,\n",
    "#             pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "#             return_tensors='pt',\n",
    "#         )\n",
    "\n",
    "#         # Reshape the batch\n",
    "#         batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "#         batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "#         return batch\n",
    "\n",
    "# # Load a pre-trained tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # Create a sample MCQ dataset\n",
    "# data = {\n",
    "#     'input_ids': [\n",
    "#         # Each question has four choices represented as lists of token IDs.\n",
    "#         [\n",
    "#             [101, 2054, 2003, 1996, 2851, 1997, 2000, 2017, 102],  # Choice 1: \"Paris\"\n",
    "#             [101, 2003, 2129, 1997, 2017, 2000, 2018, 102],  # Choice 2: \"London\"\n",
    "#             [101, 2003, 1996, 2798, 2003, 2061, 1997, 2000, 102],  # Choice 3: \"Berlin\"\n",
    "#             [101, 2054, 2003, 1996, 3451, 2000, 2017, 102],  # Choice 4: \"Madrid\"\n",
    "#         ],\n",
    "#         [\n",
    "#             [101, 2054, 2003, 1996, 2015, 2001, 2004, 102],  # Choice 1: \"3\"\n",
    "#             [101, 2054, 2003, 1996, 2040, 2001, 2004, 102],  # Choice 2: \"4\"\n",
    "#             [101, 2054, 2003, 1996, 2000, 2054, 102],  # Choice 3: \"5\"\n",
    "#             [101, 2054, 2003, 1996, 2045, 2001, 2004, 102],  # Choice 4: \"6\"\n",
    "#         ]\n",
    "#     ],\n",
    "#     'attention_mask': [\n",
    "#         [\n",
    "#             [1] * 9,  # Attention mask for Choice 1\n",
    "#             [1] * 8,  # Attention mask for Choice 2\n",
    "#             [1] * 9,  # Attention mask for Choice 3\n",
    "#             [1] * 8   # Attention mask for Choice 4\n",
    "#         ],\n",
    "#         [\n",
    "#             [1] * 8,  # Attention mask for Choice 1\n",
    "#             [1] * 8,  # Attention mask for Choice 2\n",
    "#             [1] * 7,  # Attention mask for Choice 3\n",
    "#             [1] * 8   # Attention mask for Choice 4\n",
    "#         ]\n",
    "#     ],\n",
    "#     'label': [0, 1]  # Correct answer index for each question\n",
    "# }\n",
    "\n",
    "# # Create a Dataset from the data\n",
    "# tokenized_train_ds = Dataset.from_dict(data)\n",
    "\n",
    "# # Create a DataLoader using the DataCollator\n",
    "# data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer, padding=True)\n",
    "# dataloader = DataLoader(tokenized_train_ds, batch_size=2, collate_fn=data_collator)\n",
    "\n",
    "# # Get a batch from the DataLoader\n",
    "# batch = next(iter(dataloader))\n",
    "\n",
    "# # Print the resulting batch\n",
    "# print(batch)\n",
    "\n",
    "'''\n",
    "the batch output will look like this for batch_size=1:\n",
    "\n",
    "{'input_ids': tensor([[[ 101, 2054, 2003, 1996, 2851, 1997, 2000, 2017,  102],\n",
    "         [ 101, 2003, 2129, 1997, 2017, 2000, 2018,  102,    0],\n",
    "         [ 101, 2003, 1996, 2798, 2003, 2061, 1997, 2000,  102],\n",
    "         [ 101, 2054, 2003, 1996, 3451, 2000, 2017,  102,    0]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "         [1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "         [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "         [1, 1, 1, 1, 1, 1, 1, 1, 0]]]), 'labels': tensor([0])}\n",
    "\n",
    "the batch output will look like this for batch_size=2:\n",
    "\n",
    "{'input_ids': tensor([[[ 101, 2054, 2003, 1996, 2851, 1997, 2000, 2017,  102],\n",
    "         [ 101, 2003, 2129, 1997, 2017, 2000, 2018,  102,    0],\n",
    "         [ 101, 2003, 1996, 2798, 2003, 2061, 1997, 2000,  102],\n",
    "         [ 101, 2054, 2003, 1996, 3451, 2000, 2017,  102,    0]],\n",
    "\n",
    "        [[ 101, 2054, 2003, 1996, 2015, 2001, 2004,  102,    0],\n",
    "         [ 101, 2054, 2003, 1996, 2040, 2001, 2004,  102,    0],\n",
    "         [ 101, 2054, 2003, 1996, 2000, 2054,  102,    0,    0],\n",
    "         [ 101, 2054, 2003, 1996, 2045, 2001, 2004,  102,    0]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "         [1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "         [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "         [1, 1, 1, 1, 1, 1, 1, 1, 0]],\n",
    "\n",
    "        [[1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "         [1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "         [1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "         [1, 1, 1, 1, 1, 1, 1, 1, 0]]]), 'labels': tensor([0, 1])}\n",
    "         \n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "455e3e75-3b9f-44ff-b57f-37b6ef44f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following datacollator (adapted from https://huggingface.co/docs/transformers/tasks/multiple_choice)\n",
    "# will dynamically pad our questions at batch-time so we don't have to make every question the length\n",
    "# of our longest question.\n",
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    \n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0]['input_ids'])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "57fca244",
   "metadata": {
    "papermill": {
     "duration": 18.147755,
     "end_time": "2023-07-11T01:36:51.644972",
     "exception": false,
     "start_time": "2023-07-11T01:36:33.497217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Now we'll instatiate the model that we'll finetune on our public dataset, then use to\n",
    "# make prediction on the private dataset.\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "model = AutoModelForMultipleChoice.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "abea31ac",
   "metadata": {
    "papermill": {
     "duration": 0.134215,
     "end_time": "2023-07-11T01:36:51.785177",
     "exception": false,
     "start_time": "2023-07-11T01:36:51.650962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vino/anaconda3/envs/pytorch23/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# The arguments here are selected to run quickly; feel free to play with them.\n",
    "model_dir = 'finetuned_bert'\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "2dd1d73e",
   "metadata": {
    "papermill": {
     "duration": 6.41984,
     "end_time": "2023-07-11T01:36:58.211002",
     "exception": false,
     "start_time": "2023-07-11T01:36:51.791162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generally it's a bad idea to validate on your training set, but because our training set\n",
    "# for this problem is so small we're going to train on all our data.\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_ds,\n",
    "    eval_dataset=tokenized_train_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c550ef9e",
   "metadata": {
    "papermill": {
     "duration": 54.508271,
     "end_time": "2023-07-11T01:37:52.728897",
     "exception": false,
     "start_time": "2023-07-11T01:36:58.220626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:22, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.610346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.597996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.599787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.586468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.568846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.558079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.547341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.537585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.528217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.524506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=1.6088575363159179, metrics={'train_runtime': 23.5736, 'train_samples_per_second': 0.848, 'train_steps_per_second': 0.424, 'total_flos': 616660999200.0, 'train_loss': 1.6088575363159179, 'epoch': 10.0})"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training should take about a minute\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "31c0e38d",
   "metadata": {
    "papermill": {
     "duration": 3.724407,
     "end_time": "2023-07-11T01:37:56.466514",
     "exception": false,
     "start_time": "2023-07-11T01:37:52.742107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we can actually make predictions on our questions\n",
    "predictions = trainer.predict(tokenized_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "cc327dad-a213-448b-81aa-1ace4f896d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.09753699, -0.06091017, -0.10660436, -0.02741827, -0.05923901],\n",
       "       [-0.073296  , -0.01930785, -0.10353055, -0.03636026, -0.08368777]],\n",
       "      dtype=float32), label_ids=array([0, 1]), metrics={'test_loss': 1.5245064496994019, 'test_runtime': 0.0673, 'test_samples_per_second': 29.733, 'test_steps_per_second': 14.866})"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logits\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ec82dd07-f459-48b4-a39a-2b7f6d81356f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted class\n",
    "np.argmax(predictions.predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2690174a-af3e-494c-8f77-033a7aee3b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 4, 1, 2],\n",
       "       [1, 3, 0, 4, 2]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted class in sorted manner\n",
    "np.argsort(-predictions.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "3a7ffdf5",
   "metadata": {
    "papermill": {
     "duration": 0.017959,
     "end_time": "2023-07-11T01:37:56.491471",
     "exception": false,
     "start_time": "2023-07-11T01:37:56.473512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The following function gets the indices of the highest scoring answers for each row\n",
    "# and converts them back to our answer format (A, B, C, D, E)\n",
    "import numpy as np\n",
    "def predictions_to_map_output(predictions):\n",
    "    sorted_answer_indices = np.argsort(-predictions)\n",
    "    print('sorted indices:')\n",
    "    print(sorted_answer_indices)\n",
    "    \n",
    "    top_answer_indices = sorted_answer_indices[:,:3] # Get the first three answers in each row\n",
    "    print('top answer indices:')    \n",
    "    print(top_answer_indices)\n",
    "    \n",
    "    top_answers = np.vectorize(index_to_option.get)(top_answer_indices)\n",
    "    print('top_answers:')\n",
    "    print(top_answers)\n",
    "    return np.apply_along_axis(lambda row: ' '.join(row), 1, top_answers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "25afe1ed",
   "metadata": {
    "papermill": {
     "duration": 0.02442,
     "end_time": "2023-07-11T01:37:56.523158",
     "exception": false,
     "start_time": "2023-07-11T01:37:56.498738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted indices:\n",
      "[[0 3 4 1 2]\n",
      " [1 3 0 4 2]]\n",
      "top answer indices:\n",
      "[[0 3 4]\n",
      " [1 3 0]]\n",
      "top_answers:\n",
      "[['A' 'D' 'E']\n",
      " ['B' 'D' 'A']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['A D E', 'B D A'], dtype='<U5')"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's double check our output looks correct:\n",
    "predictions_to_map_output(predictions.predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 110.037962,
   "end_time": "2023-07-11T01:38:04.418532",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-11T01:36:14.380570",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0156eb6919874f52a2aa4cc40d4b955d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "19254838c9a84410a900834a2f7faa02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1fa929175ad4417ab88806a3ed30cbcf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2aa7ca5d5f864cbe887f3ed8356e0362": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c4c7fe76e9b745328312dc8f05e8aa52",
        "IPY_MODEL_893526c3f43240d28adc06fb6461a816",
        "IPY_MODEL_380543b29e274a4c873e4234efe1acf8"
       ],
       "layout": "IPY_MODEL_987880998ee946728012682cf8fabe0f"
      }
     },
     "30b7cec1b9b5478eaf481da5df5f8b2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_88d867c2b340458d878da0cef8edf0e1",
        "IPY_MODEL_f120b9f5e1634e818ecf1ad3a7b88852",
        "IPY_MODEL_f60b56b4554940e9b18b759999ca3b45"
       ],
       "layout": "IPY_MODEL_e3d9a97384504f509cfeded51538f2f6"
      }
     },
     "380543b29e274a4c873e4234efe1acf8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d2c6e362e7644e7eb13b8908e1308604",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_19254838c9a84410a900834a2f7faa02",
       "value": " 200/200 [00:00&lt;00:00, 447.65ex/s]"
      }
     },
     "883edfac7c4946479374ded0b2f73917": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "88d867c2b340458d878da0cef8edf0e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f1c579c0b6a548f3967fe3357e73f2ae",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_0156eb6919874f52a2aa4cc40d4b955d",
       "value": "100%"
      }
     },
     "893526c3f43240d28adc06fb6461a816": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_db35501923b6462d9437279452edce40",
       "max": 200,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cb142a8777564b388cfe33d05aaf3465",
       "value": 200
      }
     },
     "8fac0e9f865d4d8cb6037d8082868b15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "987880998ee946728012682cf8fabe0f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b4691224916549cb8d937cdfbac3ac71": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c2d07dd522994641abb54728a49baebf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c4c7fe76e9b745328312dc8f05e8aa52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b4691224916549cb8d937cdfbac3ac71",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_883edfac7c4946479374ded0b2f73917",
       "value": "100%"
      }
     },
     "cb142a8777564b388cfe33d05aaf3465": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d2c6e362e7644e7eb13b8908e1308604": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "db35501923b6462d9437279452edce40": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3d9a97384504f509cfeded51538f2f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ed3868684cef49d8bbac32d09b57dc29": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f120b9f5e1634e818ecf1ad3a7b88852": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ed3868684cef49d8bbac32d09b57dc29",
       "max": 200,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8fac0e9f865d4d8cb6037d8082868b15",
       "value": 200
      }
     },
     "f1c579c0b6a548f3967fe3357e73f2ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f60b56b4554940e9b18b759999ca3b45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1fa929175ad4417ab88806a3ed30cbcf",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_c2d07dd522994641abb54728a49baebf",
       "value": " 200/200 [00:00&lt;00:00, 756.19ex/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
