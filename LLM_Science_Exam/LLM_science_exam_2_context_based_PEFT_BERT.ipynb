{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea4478ec",
   "metadata": {
    "papermill": {
     "duration": 0.005068,
     "end_time": "2023-07-11T01:36:25.324996",
     "exception": false,
     "start_time": "2023-07-11T01:36:25.319928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LLM PEFT BERT with Context Relavant Co\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b3c2e6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.057636,
     "end_time": "2023-07-11T01:36:25.387575",
     "exception": false,
     "start_time": "2023-07-11T01:36:25.329939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND is a theory that explains the missing bar...</td>\n",
       "      <td>MOND is a theory that reduces the discrepancy ...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The triskeles symbol was reconstructed as a fe...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>The triskeles symbol is a representation of a ...</td>\n",
       "      <td>The triskeles symbol represents three interloc...</td>\n",
       "      <td>The triskeles symbol is a representation of th...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What is the significance of regularization in ...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>Regularizing the mass-energy of an electron wi...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>The angular spacing of features in the diffrac...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             prompt  \\\n",
       "0   0  Which of the following statements accurately d...   \n",
       "1   1  Which of the following is an accurate definiti...   \n",
       "2   2  Which of the following statements accurately d...   \n",
       "3   3  What is the significance of regularization in ...   \n",
       "4   4  Which of the following statements accurately d...   \n",
       "\n",
       "                                                   A  \\\n",
       "0  MOND is a theory that reduces the observed mis...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "2  The triskeles symbol was reconstructed as a fe...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   B  \\\n",
       "0  MOND is a theory that increases the discrepanc...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "2  The triskeles symbol is a representation of th...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   C  \\\n",
       "0  MOND is a theory that explains the missing bar...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "2  The triskeles symbol is a representation of a ...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   D  \\\n",
       "0  MOND is a theory that reduces the discrepancy ...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "2  The triskeles symbol represents three interloc...   \n",
       "3  Regularizing the mass-energy of an electron wi...   \n",
       "4  The angular spacing of features in the diffrac...   \n",
       "\n",
       "                                                   E answer  \n",
       "0  MOND is a theory that eliminates the observed ...      D  \n",
       "1  Dynamic scaling refers to the evolution of sel...      A  \n",
       "2  The triskeles symbol is a representation of th...      A  \n",
       "3  Regularizing the mass-energy of an electron wi...      C  \n",
       "4  The angular spacing of features in the diffrac...      D  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's import the public training set and take a look\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ec0746-5048-4743-9c4d-339ede4c87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pages_df = pd.read_csv('./data/train_pages_df.csv')\n",
    "phy_pages_df = pd.read_csv('./data/physics_pages_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e138cb00-891c-4197-ba6f-bd119d85ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pages_df=pd.concat([train_pages_df,phy_pages_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db1b0c83-dc9e-410c-ba31-7a084f90642c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>section_title</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supersymmetric quantum mechanics</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>understanding consequences supersymmetry susy ...</td>\n",
       "      <td>understanding consequences supersymmetry susy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supersymmetric quantum mechanics</td>\n",
       "      <td>Example: the harmonic oscillator</td>\n",
       "      <td>schr dinger equation harmonic oscillator takes...</td>\n",
       "      <td>schr dinger equation harmonic oscillator takes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Supersymmetric quantum mechanics</td>\n",
       "      <td>Example: the harmonic oscillator</td>\n",
       "      <td>schr dinger equation harmonic oscillator takes...</td>\n",
       "      <td>special case shape invariance, discussed below...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Supersymmetric quantum mechanics</td>\n",
       "      <td>Example: the harmonic oscillator</td>\n",
       "      <td>special case shape invariance, discussed below...</td>\n",
       "      <td>schr dinger equation harmonic oscillator takes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Supersymmetric quantum mechanics</td>\n",
       "      <td>Example: the harmonic oscillator</td>\n",
       "      <td>special case shape invariance, discussed below...</td>\n",
       "      <td>special case shape invariance, discussed below...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>Negative resistance</td>\n",
       "      <td>Oscillators</td>\n",
       "      <td>Negative differential resistance devices are w...</td>\n",
       "      <td>negative differential resistance devices widel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504</th>\n",
       "      <td>Negative resistance</td>\n",
       "      <td>Amplifiers</td>\n",
       "      <td>Negative differential resistance devices such ...</td>\n",
       "      <td>negative differential resistance devices gunn ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>Negative resistance</td>\n",
       "      <td>Switching circuits</td>\n",
       "      <td>Negative differential resistance devices are a...</td>\n",
       "      <td>negative differential resistance devices also ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4506</th>\n",
       "      <td>Negative resistance</td>\n",
       "      <td>History</td>\n",
       "      <td>Negative resistance was first recognized durin...</td>\n",
       "      <td>negative resistance first recognized investiga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4507</th>\n",
       "      <td>Negative resistance</td>\n",
       "      <td>Summary</td>\n",
       "      <td>In electronics, negative resistance (NR) is a ...</td>\n",
       "      <td>electronics, negative resistance nr property e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5536 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  page                     section_title  \\\n",
       "0     Supersymmetric quantum mechanics                      Introduction   \n",
       "1     Supersymmetric quantum mechanics  Example: the harmonic oscillator   \n",
       "2     Supersymmetric quantum mechanics  Example: the harmonic oscillator   \n",
       "3     Supersymmetric quantum mechanics  Example: the harmonic oscillator   \n",
       "4     Supersymmetric quantum mechanics  Example: the harmonic oscillator   \n",
       "...                                ...                               ...   \n",
       "4503               Negative resistance                       Oscillators   \n",
       "4504               Negative resistance                        Amplifiers   \n",
       "4505               Negative resistance                Switching circuits   \n",
       "4506               Negative resistance                           History   \n",
       "4507               Negative resistance                           Summary   \n",
       "\n",
       "                                                   text  \\\n",
       "0     understanding consequences supersymmetry susy ...   \n",
       "1     schr dinger equation harmonic oscillator takes...   \n",
       "2     schr dinger equation harmonic oscillator takes...   \n",
       "3     special case shape invariance, discussed below...   \n",
       "4     special case shape invariance, discussed below...   \n",
       "...                                                 ...   \n",
       "4503  Negative differential resistance devices are w...   \n",
       "4504  Negative differential resistance devices such ...   \n",
       "4505  Negative differential resistance devices are a...   \n",
       "4506  Negative resistance was first recognized durin...   \n",
       "4507  In electronics, negative resistance (NR) is a ...   \n",
       "\n",
       "                                           cleaned_text  chunk_id  \n",
       "0     understanding consequences supersymmetry susy ...         1  \n",
       "1     schr dinger equation harmonic oscillator takes...         1  \n",
       "2     special case shape invariance, discussed below...         1  \n",
       "3     schr dinger equation harmonic oscillator takes...         1  \n",
       "4     special case shape invariance, discussed below...         1  \n",
       "...                                                 ...       ...  \n",
       "4503  negative differential resistance devices widel...         1  \n",
       "4504  negative differential resistance devices gunn ...         1  \n",
       "4505  negative differential resistance devices also ...         1  \n",
       "4506  negative resistance first recognized investiga...         1  \n",
       "4507  electronics, negative resistance nr property e...         1  \n",
       "\n",
       "[5536 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55729adf",
   "metadata": {
    "papermill": {
     "duration": 0.888982,
     "end_time": "2023-07-11T01:36:26.281400",
     "exception": false,
     "start_time": "2023-07-11T01:36:25.392418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For convenience we'll turn our pandas Dataframe into a Dataset\n",
    "from datasets import Dataset\n",
    "train_ds = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "673a67c4-97d8-48ba-984e-b209f9a09e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac098933-8185-43f2-87e4-49b9ca5bbb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'prompt': 'Which of the following statements accurately describes the impact of Modified Newtonian Dynamics (MOND) on the observed \"missing baryonic mass\" discrepancy in galaxy clusters?',\n",
       " 'A': 'MOND is a theory that reduces the observed missing baryonic mass in galaxy clusters by postulating the existence of a new form of matter called \"fuzzy dark matter.\"',\n",
       " 'B': 'MOND is a theory that increases the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions from a factor of around 10 to a factor of about 20.',\n",
       " 'C': 'MOND is a theory that explains the missing baryonic mass in galaxy clusters that was previously considered dark matter by demonstrating that the mass is in the form of neutrinos and axions.',\n",
       " 'D': 'MOND is a theory that reduces the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions from a factor of around 10 to a factor of about 2.',\n",
       " 'E': 'MOND is a theory that eliminates the observed missing baryonic mass in galaxy clusters by imposing a new mathematical formulation of gravity that does not require the existence of dark matter.',\n",
       " 'answer': 'D'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d406058",
   "metadata": {
    "papermill": {
     "duration": 2.342402,
     "end_time": "2023-07-11T01:36:28.636204",
     "exception": false,
     "start_time": "2023-07-11T01:36:26.293802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import pprint\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57fca244",
   "metadata": {
    "papermill": {
     "duration": 18.147755,
     "end_time": "2023-07-11T01:36:51.644972",
     "exception": false,
     "start_time": "2023-07-11T01:36:33.497217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Now we'll instatiate the model that we'll finetune on our public dataset, then use to\n",
    "# make prediction on the private dataset.\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "import torch\n",
    "model = AutoModelForMultipleChoice.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2621ace5-bc4f-40d5-a2ef-780948714f23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91972, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_A</th>\n",
       "      <th>sentence_B</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>understanding consequences supersymmetry susy ...</td>\n",
       "      <td>make progress problems, physicists developed s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make progress problems, physicists developed s...</td>\n",
       "      <td>hoped studying susy's consequences simpler set...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hoped studying susy's consequences simpler set...</td>\n",
       "      <td>example, students typically taught \"solve\" hyd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>example, students typically taught \"solve\" hyd...</td>\n",
       "      <td>considerable amount work using many differenti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>considerable amount work using many differenti...</td>\n",
       "      <td>outcome spectrum hydrogen atom energy states l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sentence_A  \\\n",
       "0  understanding consequences supersymmetry susy ...   \n",
       "1  make progress problems, physicists developed s...   \n",
       "2  hoped studying susy's consequences simpler set...   \n",
       "3  example, students typically taught \"solve\" hyd...   \n",
       "4  considerable amount work using many differenti...   \n",
       "\n",
       "                                          sentence_B label  \n",
       "0  make progress problems, physicists developed s...     1  \n",
       "1  hoped studying susy's consequences simpler set...     1  \n",
       "2  example, students typically taught \"solve\" hyd...     1  \n",
       "3  considerable amount work using many differenti...     1  \n",
       "4  outcome spectrum hydrogen atom energy states l...     1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def prepare_nsp_data(corpus, max_samples=None):\n",
    "    # Step 1: Split the corpus into sentences\n",
    "    sentences = sent_tokenize(corpus)\n",
    "    \n",
    "    # Step 2: Create positive pairs (consecutive sentences)\n",
    "    positive_pairs = [(sentences[i], sentences[i+1], 1) for i in range(len(sentences) - 1)]\n",
    "    \n",
    "    # Step 3: Create negative pairs (randomly picked second sentence)\n",
    "    negative_pairs = []\n",
    "    for i in range(len(sentences) - 1):\n",
    "        sentence_A = sentences[i]\n",
    "        random_sentence_B = random.choice(sentences)\n",
    "        \n",
    "        # Ensure sentence_B is not the actual next sentence\n",
    "        while random_sentence_B == sentences[i + 1]:\n",
    "            random_sentence_B = random.choice(sentences)\n",
    "            \n",
    "        negative_pairs.append((sentence_A, random_sentence_B, 0))\n",
    "    \n",
    "    # Combine positive and negative pairs\n",
    "    dataset = positive_pairs + negative_pairs\n",
    "    \n",
    "    # Step 4: Optionally, limit the number of samples\n",
    "    if max_samples:\n",
    "        dataset = random.sample(dataset, max_samples)\n",
    "    \n",
    "    # Convert to a DataFrame for easy saving or manipulation\n",
    "    df = pd.DataFrame(dataset, columns=[\"sentence_A\", \"sentence_B\", \"label\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "dfs=[]\n",
    "for i in range(train_pages_df.shape[0]):\n",
    "    df=prepare_nsp_data(train_pages_df['cleaned_text'].iloc[i])\n",
    "    dfs.append(df)\n",
    "combined_df = pd.concat(dfs, ignore_index=True)    \n",
    "# Saving the dataset to a .csv file for BERT NSP training\n",
    "#df.to_csv(\"nsp_training_data.csv\", sep=\"\\t\", index=False)\n",
    "print(combined_df.shape)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "121cf05c-e8b7-4c3e-96dc-b1a433f7dbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dataset: 91972\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Custom Dataset class for BERT NSP task\n",
    "class BertNSPDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get sentence A, sentence B, and label\n",
    "        sentence_A = self.data.iloc[index]['sentence_A']\n",
    "        sentence_B = self.data.iloc[index]['sentence_B']\n",
    "        label = self.data.iloc[index]['label']\n",
    "        \n",
    "        # Encode sentence pair using BERT tokenizer\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence_A,\n",
    "            sentence_B,\n",
    "            add_special_tokens=True,       # Add [CLS], [SEP]\n",
    "            max_length=self.max_len,       # Maximum length of the input sequence\n",
    "            return_token_type_ids=True,    # Necessary for sentence pairs\n",
    "            padding='max_length',          # Pad up to the max length\n",
    "            truncation=True,               # Truncate sentences to the max length\n",
    "            return_attention_mask=True,    # Create attention mask\n",
    "            return_tensors='pt'            # Return PyTorch tensors\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)  # Convert label to tensor\n",
    "        }\n",
    "\n",
    "# Function to prepare the dataset\n",
    "def create_nsp_dataset(df, tokenizer, max_len=128):\n",
    "    return BertNSPDataset(df, tokenizer, max_len)\n",
    "\n",
    "# Example of using the dataset\n",
    "max_len = 128  # Max length of the input sequence\n",
    "\n",
    "# Create the dataset\n",
    "nsp_dataset = create_nsp_dataset(combined_df, tokenizer, max_len)\n",
    "\n",
    "nsp_dataset_mini = create_nsp_dataset(combined_df.iloc[:128], tokenizer, max_len)\n",
    "\n",
    "print('len of dataset:',len(nsp_dataset))\n",
    "# Optionally, use DataLoader for batching\n",
    "dataloader = DataLoader(nsp_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bba0713-40ec-4211-aa9c-902bc3fea2b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vino/anaconda3/envs/pytorch23/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 109,778,690 || trainable%: 0.2686\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:22, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.768194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8, training_loss=6.721007347106934, metrics={'train_runtime': 25.3182, 'train_samples_per_second': 5.056, 'train_steps_per_second': 0.316, 'total_flos': 8448544800768.0, 'train_loss': 6.721007347106934, 'epoch': 1.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForNextSentencePrediction, BertTokenizer, Trainer, TrainingArguments\n",
    "from peft import PeftConfig, PeftModel\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import torch\n",
    "\n",
    "# Initialize BERT with Next Sentence Prediction head\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Prepare PEFT configuration (for LoRA in this case)\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,  # NSP task\n",
    "    r=8,                                         # Low-rank factor\n",
    "    lora_alpha=32,                               # Scaling factor\n",
    "    lora_dropout=0.1,                            # Dropout for LoRA\n",
    "    target_modules=[\"query\", \"value\"],           # Target attention layers\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Verify the trainable parameters\n",
    "peft_model.print_trainable_parameters()\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./data/peft/\",       # Output directory\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate at the end of every epoch\n",
    "    learning_rate=5e-5,           # Learning rate\n",
    "    per_device_train_batch_size=16,   # Batch size for training\n",
    "    per_device_eval_batch_size=16,    # Batch size for evaluation\n",
    "    num_train_epochs=1,           # Number of epochs\n",
    "    weight_decay=0.001,            # Weight decay\n",
    "    logging_dir='./logs',         # Directory for logging\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "# DataLoader already prepared\n",
    "# `nsp_dataset` should be prepared as discussed in the previous steps\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=peft_model,             # PEFT BERT model with LoRA\n",
    "    args=training_args,           # Training arguments\n",
    "    train_dataset=nsp_dataset_mini,    # Training dataset\n",
    "    eval_dataset=nsp_dataset_mini,     # Evaluation dataset (you can split the data if needed)\n",
    "    tokenizer=tokenizer           # Tokenizer\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a4d1ee1-61ff-4544-aeaa-f9cbdcf66cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "### model trained in GPU. Load the trained model\n",
    "### only 2 training epochs are done \n",
    "### to show model improvement over plain-BERT\n",
    "model = AutoModelForMultipleChoice.from_pretrained('./data/peft/checkpoint-11000/')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./data/peft/checkpoint-11000/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "362676fe-0183-48f0-b730-fabe59d5303f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2158dc3bc8464aa1dc7340cc79137d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We'll create a dictionary to convert option names (A, B, C, D, E) into indices and back again\n",
    "options = 'ABCDE'\n",
    "indices = list(range(5))\n",
    "\n",
    "option_to_index = {option: index for option, index in zip(options, indices)}\n",
    "index_to_option = {index: option for option, index in zip(options, indices)}\n",
    "\n",
    "def preprocess(example):\n",
    "    # The AutoModelForMultipleChoice class expects a set of question/answer pairs\n",
    "    # so we'll copy our question 5 times before tokenizing\n",
    "    first_sentence = [example['prompt']] * 5\n",
    "    \n",
    "    second_sentence = []\n",
    "    for option in options:\n",
    "        second_sentence.append(example[option])\n",
    "    \n",
    "    # Our tokenizer will turn our text into token IDs BERT can understand\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentence, padding='max_length', truncation=True, max_length=128)\n",
    "    tokenized_example['label'] = option_to_index[example['answer']]\n",
    "\n",
    "    return tokenized_example\n",
    "\n",
    "tokenized_train_ds = train_ds.map(preprocess, batched=False, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72be02ea-5dd7-4fb2-b712-aafc77128e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions\n",
    "def predict_mcq(example, model):\n",
    "    predictions = []\n",
    "    \n",
    "    # Extract necessary inputs from dataset\n",
    "    input_ids = torch.tensor(example['input_ids']).unsqueeze(0)  # Add batch dimension\n",
    "    attention_mask = torch.tensor(example['attention_mask']).unsqueeze(0)\n",
    "    token_type_ids = torch.tensor(example['token_type_ids']).unsqueeze(0)\n",
    "        \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "    logits = outputs.logits\n",
    "    predicted_index = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    return predicted_index\n",
    "\n",
    "# Run prediction over the dataset\n",
    "pred_idx=[]\n",
    "for data in tokenized_train_ds:\n",
    "     pred_idx.append(predict_mcq(data , model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbbdb1d2-9792-4b2b-9e53-8f27d21df5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted answer\n",
    "option_mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}\n",
    "prediction = [option_mapping[i] for i in pred_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be6b6d95-8df9-4242-aea5-161eab0428b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predicted_answer']=prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89ed2847-b3aa-4e93-a928-f7c15dca4440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(train_df.shape[0]):\n",
    "    if (train_df['answer'].iloc[i]==train_df['predicted_answer'].iloc[i]):\n",
    "        count=count+1\n",
    "print(count/200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2c6ca-d911-4661-b875-22d5e4f10679",
   "metadata": {},
   "source": [
    "### BERT with PEFT (context data) improves from 0.18 to 0.28\n",
    "#### context relavant corpus data converted to NSP daatset. Model only trained for 2 epochs on NSP style daatset. Further training may improve the accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 110.037962,
   "end_time": "2023-07-11T01:38:04.418532",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-11T01:36:14.380570",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0156eb6919874f52a2aa4cc40d4b955d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "19254838c9a84410a900834a2f7faa02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1fa929175ad4417ab88806a3ed30cbcf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2aa7ca5d5f864cbe887f3ed8356e0362": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c4c7fe76e9b745328312dc8f05e8aa52",
        "IPY_MODEL_893526c3f43240d28adc06fb6461a816",
        "IPY_MODEL_380543b29e274a4c873e4234efe1acf8"
       ],
       "layout": "IPY_MODEL_987880998ee946728012682cf8fabe0f"
      }
     },
     "30b7cec1b9b5478eaf481da5df5f8b2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_88d867c2b340458d878da0cef8edf0e1",
        "IPY_MODEL_f120b9f5e1634e818ecf1ad3a7b88852",
        "IPY_MODEL_f60b56b4554940e9b18b759999ca3b45"
       ],
       "layout": "IPY_MODEL_e3d9a97384504f509cfeded51538f2f6"
      }
     },
     "380543b29e274a4c873e4234efe1acf8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d2c6e362e7644e7eb13b8908e1308604",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_19254838c9a84410a900834a2f7faa02",
       "value": " 200/200 [00:00&lt;00:00, 447.65ex/s]"
      }
     },
     "883edfac7c4946479374ded0b2f73917": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "88d867c2b340458d878da0cef8edf0e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f1c579c0b6a548f3967fe3357e73f2ae",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_0156eb6919874f52a2aa4cc40d4b955d",
       "value": "100%"
      }
     },
     "893526c3f43240d28adc06fb6461a816": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_db35501923b6462d9437279452edce40",
       "max": 200,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cb142a8777564b388cfe33d05aaf3465",
       "value": 200
      }
     },
     "8fac0e9f865d4d8cb6037d8082868b15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "987880998ee946728012682cf8fabe0f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b4691224916549cb8d937cdfbac3ac71": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c2d07dd522994641abb54728a49baebf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c4c7fe76e9b745328312dc8f05e8aa52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b4691224916549cb8d937cdfbac3ac71",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_883edfac7c4946479374ded0b2f73917",
       "value": "100%"
      }
     },
     "cb142a8777564b388cfe33d05aaf3465": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d2c6e362e7644e7eb13b8908e1308604": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "db35501923b6462d9437279452edce40": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3d9a97384504f509cfeded51538f2f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ed3868684cef49d8bbac32d09b57dc29": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f120b9f5e1634e818ecf1ad3a7b88852": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ed3868684cef49d8bbac32d09b57dc29",
       "max": 200,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8fac0e9f865d4d8cb6037d8082868b15",
       "value": 200
      }
     },
     "f1c579c0b6a548f3967fe3357e73f2ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f60b56b4554940e9b18b759999ca3b45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1fa929175ad4417ab88806a3ed30cbcf",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_c2d07dd522994641abb54728a49baebf",
       "value": " 200/200 [00:00&lt;00:00, 756.19ex/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
